{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439a2d1d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# POC semantic search E2E analysis\n",
    "\n",
    "The goal of this POC notebook is to import a model from hugging face, apply it to the dataset, evaluate on metrics, benchmark and create some visualisations. Essentially make sure the semantic search is working end to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36657807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ranx import Qrels, Run, evaluate\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb759127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examples = pd.read_parquet('../data/shopping_queries_dataset_examples.parquet')\n",
    "df_products = pd.read_parquet('../data/shopping_queries_dataset_products.parquet')\n",
    "df_sources = pd.read_csv(\"../data/shopping_queries_dataset_sources.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5eeb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/amazon-science/esci-data: suggested filter for task 1: Query-Product Ranking \n",
    "# Query-Product Ranking: Given a user specified query and a list of matched products, the goal of this \n",
    "# task is to rank the products so that the relevant products are ranked above the non-relevant ones.\n",
    "df_examples_products = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "df_task_1 = df_examples_products[df_examples_products[\"small_version\"] == 1]\n",
    "df_task_1_train = df_task_1[df_task_1[\"split\"] == \"train\"]\n",
    "df_task_1_test = df_task_1[df_task_1[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39b94230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ellen\\anaconda3\\envs\\venv-semantic-search\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ellen\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# use code provided on huggingface to get started on multilingual text \n",
    "# semantic search siamese bert\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "# most basic: TF-IDF\n",
    "# BM25: bm25 = BM25Okapi(tokenized_docs)\n",
    "# try siamese BERT: SeyedAli/Multilingual-Text-Semantic-Search-Siamese-BERT-V1\n",
    "# try sentence-transformers/paraphrase-MiniLM-L6-v2 - sentence-BERT\n",
    "# try contextualised late interaction over BERT:\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = ColBERT.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "df_task_1_train_light = df_task_1_train[df_task_1_train['query_id'].isin([1,2,3,4])]\n",
    "\n",
    "query_embeddings = model.encode(df_task_1_train_light['query'].tolist(), convert_to_tensor=True)\n",
    "example_embeddings = model.encode(df_task_1_train_light['product_title'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d038835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellen\\AppData\\Local\\Temp\\ipykernel_11768\\2807857632.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  similarities_mx = cosine_similarity(np.array(query_embeddings), np.array(example_embeddings))\n"
     ]
    }
   ],
   "source": [
    "# calculate cosine similarity and get diagonal\n",
    "similarities_mx = cosine_similarity(np.array(query_embeddings), np.array(example_embeddings))\n",
    "similarities_diag = np.diag(similarities_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acbb4ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellen\\AppData\\Local\\Temp\\ipykernel_11768\\831736960.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_task_1_train_light['relevance'] = df_task_1_train_light['esci_label'].map(esci_weighting)\n"
     ]
    }
   ],
   "source": [
    "# apply esci mapping to esci label\n",
    "esci_weighting = {\n",
    "    'E': 3,\n",
    "    'S': 2,\n",
    "    'C': 1,\n",
    "    'I': 0\n",
    "}\n",
    "\n",
    "df_task_1_train_light['relevance'] = df_task_1_train_light['esci_label'].map(esci_weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cefabe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update index of subset df\n",
    "df_task_1_train_light = df_task_1_train_light.reset_index(drop=True)\n",
    "df_task_1_train_light.index = df_task_1_train_light.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbecc4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 1\n",
      "0.67, example id 16\n",
      "0.62, example id 22\n",
      "0.60, example id 24\n",
      "0.59, example id 23\n",
      "0.59, example id 28\n",
      "Query ID: 3\n",
      "0.73, example id 103\n",
      "0.67, example id 70\n",
      "0.64, example id 89\n",
      "0.62, example id 101\n",
      "0.62, example id 90\n",
      "0.5896747418894506\n"
     ]
    }
   ],
   "source": [
    "qrels_dict = {}\n",
    "run_dict = {}\n",
    "top_n = 5\n",
    "\n",
    "for query_id, group in df_task_1_train_light.groupby(\"query_id\"):\n",
    "    query_id_str = str(query_id)\n",
    "    # get actuals\n",
    "    qrels_dict[query_id_str] = {str(example): int(relevance) for example, relevance in zip(group[\"example_id\"], group[\"relevance\"])}\n",
    "    \n",
    "    # get scores paired to each example\n",
    "    examples = group[\"example_id\"].tolist()\n",
    "    example_score_pairs = list(zip(examples, similarities_diag[:len(examples)]))\n",
    "    \n",
    "    # filter for top_n examples per query\n",
    "    example_score_pairs_top_k = sorted(example_score_pairs, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # get predicted\n",
    "    run_dict[query_id_str] = {str(example): score for example, score in example_score_pairs}\n",
    "    \n",
    "    print(f\"Query ID: {query_id}\")\n",
    "    for example, score in example_score_pairs_top_k:\n",
    "        print(f\"{score:.2f}, example id {example}\")\n",
    "\n",
    "qrels = Qrels(qrels_dict)\n",
    "run = Run(run_dict)\n",
    "\n",
    "results = evaluate(qrels, run, metrics=[\"ndcg@10\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab19e4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-semantic-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
