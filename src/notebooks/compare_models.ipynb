{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350c32e6",
   "metadata": {},
   "source": [
    "# Model analysis\n",
    "\n",
    "The goal of this notebook is to import all relevant models and compare the metrics on a subset of the dataset to decide on the best model. The primary reason for using a subset of the dataset is because doc_embeddings take too long to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eea48d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd40401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import load_dataset, preprocess_dataset\n",
    "from evaluation import compute_similarity_scores, compute_metrics\n",
    "from visualisation import visualise_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b69cdb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f81e4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top models recommended on sbert (top 5, sorted by performance semantic search), performance >45\n",
    "models_to_test_clean = [\n",
    "    'multi-qa-mpnet-base-dot-v1',\n",
    "    'multi-qa-distilbert-cos-v1',\n",
    "    'multi-qa-MiniLM-L6-cos-v1',\n",
    "    'all-MiniLM-L12-v2',\n",
    "    'all-MiniLM-L6-v2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6462051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/multi-qa-distilbert-cos-v1\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L12-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# top models recommended on sbert (top 5, sorted by performance semantic search), performance >45\n",
    "models_to_test_strings = [\n",
    "    'sentence-transformers/multi-qa-mpnet-base-dot-v1',\n",
    "    'sentence-transformers/multi-qa-distilbert-cos-v1',\n",
    "    'sentence-transformers/multi-qa-MiniLM-L6-cos-v1',\n",
    "    'sentence-transformers/all-MiniLM-L12-v2',\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',\n",
    "]\n",
    "\n",
    "models_to_test_list = []\n",
    "for model in models_to_test_strings:\n",
    "    # wrap in SentenceTransformer\n",
    "    model_wrapped = SentenceTransformer(model)\n",
    "    models_to_test_list.append(model_wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf490171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "df_examples = pd.read_parquet('c:\\\\Users\\\\ellen\\\\Documents\\\\semantic-search-eval\\\\src\\\\data/shopping_queries_dataset_examples.parquet')\n",
    "df_products = pd.read_parquet('c:\\\\Users\\\\ellen\\\\Documents\\\\semantic-search-eval\\\\src\\\\data/shopping_queries_dataset_products.parquet')\n",
    "\n",
    "# https://github.com/amazon-science/esci-data: suggested filter for task 1: Query-Product Ranking \n",
    "# Query-Product Ranking: Given a user specified query and a list of matched products, the goal of this \n",
    "# task is to rank the products so that the relevant products are ranked above the non-relevant ones.\n",
    "df_examples_products = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "# take the small version for this task\n",
    "df_task_1_all = df_examples_products[df_examples_products[\"small_version\"] == 1]\n",
    "df_task_1_train = df_task_1_all[df_task_1_all[\"split\"] == \"train\"]\n",
    "\n",
    "# split into locale\n",
    "df_task_1_train_us = df_task_1_train[df_task_1_train['product_locale'] == 'us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0376557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:There are 419653 rows in this dataset.\n",
      "INFO:root:There are 1619 duplicates in this dataset.\n",
      "INFO:root:There are 418034 deduplicated rows in this dataset.\n",
      "INFO:root:There are 208220 nan product descriptions in this dataset.\n",
      "INFO:root:There are 209814 non-nan product descriptions in this dataset.\n",
      "c:\\Users\\ellen\\Documents\\semantic-search-eval\\src\\notebooks\\..\\preprocess.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not_nan['relevance'] = df_not_nan['esci_label'].map(esci_weighting)\n",
      "c:\\Users\\ellen\\Documents\\semantic-search-eval\\src\\notebooks\\..\\preprocess.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not_nan['product_doc'] = df_not_nan['product_title'] + ' ' + df_not_nan['product_description']\n",
      "INFO:root:We are expecting 5 columns in the preprocessed df.\n",
      "INFO:root:There are 7 columns in the preprocessed df\n"
     ]
    }
   ],
   "source": [
    "df_train_clean = preprocess_dataset(df_task_1_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01e590dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique query ids and sample 50 of them\n",
    "unique_query_ids = df_train_clean['query_id'].unique()\n",
    "random_query_ids = pd.Series(unique_query_ids).sample(n=200, random_state=42).tolist()\n",
    "df_train_clean_sample = df_train_clean[df_train_clean['query_id'].isin(random_query_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc691c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 68/68 [00:17<00:00,  3.94it/s]\n",
      "Batches: 100%|██████████| 68/68 [10:26<00:00,  9.21s/it]\n",
      "INFO:root:Embeddings complete\n",
      "INFO:root:Query shape: torch.Size([2158, 768])\n",
      "INFO:root:Doc shape: torch.Size([2158, 768])\n",
      "INFO:root:Similarities matrix shape: torch.Size([2158])\n",
      "C:\\Users\\ellen\\AppData\\Local\\Temp\\ipykernel_22492\\1004165216.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_clean_sample['similarity_scores'] = similarity_scores\n",
      "INFO:root:Create qrels object\n",
      "INFO:root:Create run object\n",
      "INFO:root:Calculate metrics\n",
      "Batches: 100%|██████████| 68/68 [00:06<00:00, 10.19it/s]\n",
      "Batches: 100%|██████████| 68/68 [04:37<00:00,  4.08s/it]\n",
      "INFO:root:Embeddings complete\n",
      "INFO:root:Query shape: torch.Size([2158, 768])\n",
      "INFO:root:Doc shape: torch.Size([2158, 768])\n",
      "INFO:root:Similarities matrix shape: torch.Size([2158])\n",
      "INFO:root:Create qrels object\n",
      "INFO:root:Create run object\n",
      "INFO:root:Calculate metrics\n",
      "Batches: 100%|██████████| 68/68 [00:02<00:00, 28.28it/s]\n",
      "Batches: 100%|██████████| 68/68 [01:31<00:00,  1.34s/it]\n",
      "INFO:root:Embeddings complete\n",
      "INFO:root:Query shape: torch.Size([2158, 384])\n",
      "INFO:root:Doc shape: torch.Size([2158, 384])\n",
      "INFO:root:Similarities matrix shape: torch.Size([2158])\n",
      "INFO:root:Create qrels object\n",
      "INFO:root:Create run object\n",
      "INFO:root:Calculate metrics\n",
      "Batches: 100%|██████████| 68/68 [00:04<00:00, 14.74it/s]\n",
      "Batches: 100%|██████████| 68/68 [00:53<00:00,  1.27it/s]\n",
      "INFO:root:Embeddings complete\n",
      "INFO:root:Query shape: torch.Size([2158, 384])\n",
      "INFO:root:Doc shape: torch.Size([2158, 384])\n",
      "INFO:root:Similarities matrix shape: torch.Size([2158])\n",
      "INFO:root:Create qrels object\n",
      "INFO:root:Create run object\n",
      "INFO:root:Calculate metrics\n",
      "Batches: 100%|██████████| 68/68 [00:02<00:00, 28.00it/s]\n",
      "Batches: 100%|██████████| 68/68 [00:51<00:00,  1.32it/s]\n",
      "INFO:root:Embeddings complete\n",
      "INFO:root:Query shape: torch.Size([2158, 384])\n",
      "INFO:root:Doc shape: torch.Size([2158, 384])\n",
      "INFO:root:Similarities matrix shape: torch.Size([2158])\n",
      "INFO:root:Create qrels object\n",
      "INFO:root:Create run object\n",
      "INFO:root:Calculate metrics\n"
     ]
    }
   ],
   "source": [
    "similarity_scores_list = []\n",
    "ndcg_list = []\n",
    "recall_list = []\n",
    "mrr_list = []\n",
    "\n",
    "for model in models_to_test_list:\n",
    "    similarity_scores = compute_similarity_scores(model, df_train_clean_sample)\n",
    "    df_train_clean_sample['similarity_scores'] = similarity_scores\n",
    "    ndcg10, recall10, mrr10 = compute_metrics(df_train_clean_sample)\n",
    "    similarity_scores_list.append(similarity_scores)\n",
    "    ndcg_list.append(ndcg10)\n",
    "    recall_list.append(recall10)\n",
    "    mrr_list.append(mrr10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fd2835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(index=models_to_test_clean)\n",
    "# df_results['similarity_scores'] = similarity_scores_list\n",
    "df_results['ndcg@10'] = ndcg_list\n",
    "df_results['recall@10'] = recall_list\n",
    "df_results['mrr@10'] = mrr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16339bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg@10</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>mrr@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multi-qa-mpnet-base-dot-v1</th>\n",
       "      <td>0.893274</td>\n",
       "      <td>0.857138</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-qa-distilbert-cos-v1</th>\n",
       "      <td>0.881114</td>\n",
       "      <td>0.856439</td>\n",
       "      <td>0.933131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-qa-MiniLM-L6-cos-v1</th>\n",
       "      <td>0.887377</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.944681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all-MiniLM-L12-v2</th>\n",
       "      <td>0.887035</td>\n",
       "      <td>0.853035</td>\n",
       "      <td>0.927208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.884412</td>\n",
       "      <td>0.858878</td>\n",
       "      <td>0.928839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ndcg@10  recall@10    mrr@10\n",
       "multi-qa-mpnet-base-dot-v1  0.893274   0.857138  0.955000\n",
       "multi-qa-distilbert-cos-v1  0.881114   0.856439  0.933131\n",
       "multi-qa-MiniLM-L6-cos-v1   0.887377   0.857062  0.944681\n",
       "all-MiniLM-L12-v2           0.887035   0.853035  0.927208\n",
       "all-MiniLM-L6-v2            0.884412   0.858878  0.928839"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-semantic-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
