{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88bb187",
   "metadata": {},
   "source": [
    "# Amazon ESCI dataset EDA\n",
    "\n",
    "The goal of this notebook is to identify how this dataset was created, any interesting features, benchmarks, and metrics used to evaluate it. Also, some simple EDA was performed to see distribution of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74c90587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from ranx import Qrels, Run, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b813f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examples = pd.read_parquet('../data/shopping_queries_dataset_examples.parquet')\n",
    "df_products = pd.read_parquet('../data/shopping_queries_dataset_products.parquet')\n",
    "df_sources = pd.read_csv(\"../data/shopping_queries_dataset_sources.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5645cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/amazon-science/esci-data: suggested filter for task 1: Query-Product Ranking \n",
    "# Query-Product Ranking: Given a user specified query and a list of matched products, the goal of this \n",
    "# task is to rank the products so that the relevant products are ranked above the non-relevant ones.\n",
    "df_examples_products = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "df_task_1 = df_examples_products[df_examples_products[\"small_version\"] == 1]\n",
    "df_task_1_train = df_task_1[df_task_1[\"split\"] == \"train\"]\n",
    "df_task_1_test = df_task_1[df_task_1[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf0c7e",
   "metadata": {},
   "source": [
    "# simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "172cc8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>small_version</th>\n",
       "      <th>large_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.118011e+06</td>\n",
       "      <td>1.118011e+06</td>\n",
       "      <td>1118011.0</td>\n",
       "      <td>1118011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.376919e+06</td>\n",
       "      <td>6.963481e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.195697e+05</td>\n",
       "      <td>4.190752e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.453855e+05</td>\n",
       "      <td>3.202900e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.405883e+06</td>\n",
       "      <td>7.142900e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.159588e+06</td>\n",
       "      <td>1.106680e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.621255e+06</td>\n",
       "      <td>1.306490e+05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         example_id      query_id  small_version  large_version\n",
       "count  1.118011e+06  1.118011e+06      1118011.0      1118011.0\n",
       "mean   1.376919e+06  6.963481e+04            1.0            1.0\n",
       "std    8.195697e+05  4.190752e+04            0.0            0.0\n",
       "min    1.600000e+01  1.000000e+00            1.0            1.0\n",
       "25%    6.453855e+05  3.202900e+04            1.0            1.0\n",
       "50%    1.405883e+06  7.142900e+04            1.0            1.0\n",
       "75%    2.159588e+06  1.106680e+05            1.0            1.0\n",
       "max    2.621255e+06  1.306490e+05            1.0            1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe\n",
    "df_task_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64763136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_locale\n",
       "us    601354\n",
       "jp    297883\n",
       "es    218774\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split of queries per product location\n",
    "df_task_1.product_locale.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97002b",
   "metadata": {},
   "source": [
    "### Align values to dataset description\n",
    "Check the counts match what was shown on: https://github.com/amazon-science/esci-data\n",
    "![reduced-dataset-count-product-locale](imgs/dataset_total.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62caa4cf",
   "metadata": {},
   "source": [
    "### Dataset understanding\n",
    "\n",
    "Each query_id is unique to a user search. \\\n",
    "Each judgement is a product that got manually evaluated per query_id. For e.g. 35 products were shown to the user for a given query. \\\n",
    "The depth is the count of the number of products that were evaluated per query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5b7786d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average judgements per query 23.14722567287785\n",
      "Max judgements per query 188\n",
      "Min judgements per query 8\n"
     ]
    }
   ],
   "source": [
    "# average queries per judgement\n",
    "print(\"Average judgements per query\", df_task_1.groupby('query_id')['example_id'].nunique().mean())\n",
    "print(\"Max judgements per query\", df_task_1.groupby('query_id')['example_id'].nunique().max())\n",
    "print(\"Min judgements per query\", df_task_1.groupby('query_id')['example_id'].nunique().min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3257c",
   "metadata": {},
   "source": [
    "### ESCI understanding\n",
    "- E: Exact\n",
    "- S: Substitute\n",
    "- C: Complement\n",
    "- I: Irrelevant\n",
    "\n",
    "These provide rough ranks for the judgements per query_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f944e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "esci_label\n",
       "C    0.053341\n",
       "E    0.437810\n",
       "I    0.163013\n",
       "S    0.345836\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average esci ratio for each query_id\n",
    "esci_counts = df_task_1.groupby(['query_id', 'esci_label']).size().unstack(fill_value=0)\n",
    "esci_ratios = esci_counts.div(esci_counts.sum(axis=1), axis=0)\n",
    "avg_esci_ratio = esci_ratios.mean(axis=0)\n",
    "\n",
    "avg_esci_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492d55d",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "Amazon trained and finetuned a BERT model to evaluate on the amazon-esci dataset. They use this dataset for three use cases - query product ranking, multiclass product classification and product substitute identification. For their first use case, they fine tuned a MS MARCO Cross-Encoder for the us locale. For their es and jp locales, they finetuned a multilingual MPNet. \n",
    "\n",
    "![dataset-benchmark](imgs/amazon_finetune_results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b163f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
